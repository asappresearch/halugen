from tools.args import ArgParser

from prompts.prompt_simulate import simulate
import os
import random
import json
import logging
import time
from copy import deepcopy

random.seed(1234)

def halueval_data_loader(input_path) -> dict:
    data = [json.loads(l) for l in open(input_path).readlines()]
    new_data = []
    for d in data:
        new_data.append(
                {
                    "grounding": """You are a chatbot. Your goal is to continue the conversation by responding to user's last utterance.

You have the following knowledge that can be used to generate your response:

""" + d["knowledge"],
                    "input": d["dialogue_history"],
                    "ground_truth_output": d["right_response"],
                    "hallucinated_response": d["hallucinated_response"]
                }
            )
    return new_data


def processing(args):
    total_cost = 0
    # load data
    data_list = halueval_data_loader(args.input_path)

    output_path = f"{args.output}/simulated_responses.{args.base_model}.json"
    if not os.path.exists(args.output):
        os.makedirs(args.output)

    # inference
    if args.num_input == -1:
        args.num_input = len(data_list)
    data_list = data_list[:args.num_input]

    # try to load from the output file to skip generated indices.
    simulation_data_list = []
    simulated_indices = set()
    if os.path.exists(output_path):
        simulation_data_list = json.loads(open(output_path).read())
        for d in simulation_data_list:
            if d['index'] not in simulated_indices:
                simulated_indices.add(d['index'])
            total_cost += d["cost (usd)"]

    for i_d, d in enumerate(data_list):

        logging.info(f">>>>>> data {i_d} / {len(data_list)} | simulating >>>>>> ")
        if i_d in simulated_indices:
            continue

        # simulation
        output = ""
        while output == "":
            try:
                output, price = simulate(d['input'], d['grounding'], args.base_model, args.temp)
            except:
                logging.info("fail to connect to OpenAI, wait for 10 secs and then retry")
                time.sleep(10)


        logging.info(f"data {i_d} / {len(data_list)}, generating output: {output}")

        simulation_data_list.append(deepcopy(d))
        simulation_data_list[-1]["index"] = i_d
        simulation_data_list[-1]["method"] = "simulation"
        simulation_data_list[-1]["base_model"] = args.base_model
        simulation_data_list[-1]["cost (usd)"] = price
        simulation_data_list[-1]["system_output"] = output

        total_cost += price
        open(output_path, "w").write(json.dumps(simulation_data_list, indent=4))
        logging.info(f"<<<<<< generated by simulation <<<<<<")

        logging.info(f"-------total cost: USD {total_cost}--------")


if __name__ == "__main__":
    parser = ArgParser(description="Generate simulated output given data input")
    parser.add_argument(
        "--input_path",
        default="../data/origin_data/HaluEval/data/dialogue_data.json"
    )
    parser.add_argument(
        "--num_input",
        default=-1,
        type=int,
        help="end data index to generate. The data[:num_input] are used"
    )
    parser.add_argument(
        "--temp",
        default=0.0,
        type=int,
        help="end data index to generate. The data[:num_input] are used"
    )
    parser.add_argument(
        "--base_model",
        default="gpt-4-1106-preview",
        choices=["gpt-4", "gpt-4-1106-preview", "gpt-4-0613", "gpt-4-0314",
                 "gpt-3.5-turbo", "gpt-3.5-turbo-1106", "gpt-3.5-turbo-0301", "gpt-3.5-turbo-0613",
                 "gpt-3.5-turbo-16k", "gpt-3.5-turbo-16k-0613"]
    )
    parser.add_argument(
        "--output",
        default="outputs_opendialkg"
    )

    args = parser.parse_args()
    processing(args)
